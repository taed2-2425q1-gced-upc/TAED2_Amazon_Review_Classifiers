{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "023d00e4",
      "metadata": {
        "id": "023d00e4"
      },
      "source": [
        "# This a sentiment analysis task that  design and optimization of the model, as well as potentially utilizing advanced NLP techniques such as fine-tuning pre-trained models like BERT. In a local Python environment where you can use TensorFlow and Keras, I took an optimized approach using a more complex LSTM model, incorporating some advanced techniques that help improve the accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb52f311",
      "metadata": {
        "id": "cb52f311"
      },
      "source": [
        "## Import Libraries:\n",
        "\n",
        "#### numpy and tensorflow are foundational libraries for numerical operations and machine learning.\n",
        "#### Classes imported from tensorflow.keras are used to build neural network models:\n",
        "- Sequential for linear stacking of layers.\n",
        "- Embedding, LSTM, Dense, Dropout, and Bidirectional for different types of neural network layers.\n",
        "- Tokenizer and pad_sequences are utilities for text processing.\n",
        "- train_test_split from sklearn is used for splitting data into training and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "214a844b",
      "metadata": {
        "id": "214a844b"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.initializers import Constant\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need TensorFlow version 2.10.0 to make the model work."
      ],
      "metadata": {
        "id": "b6idXs6BrZV7"
      },
      "id": "b6idXs6BrZV7"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c01d5192",
      "metadata": {
        "id": "c01d5192",
        "outputId": "674c3899-20bd-49eb-f131-1344d5a82f75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow is already version 2.10.0\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Check if TensorFlow is already version 2.10.0\n",
        "if tf.__version__ == '2.10.0':\n",
        "    print(\"TensorFlow is already version 2.10.0\")\n",
        "else:\n",
        "    print(f\"Current TensorFlow version: {tf.__version__}. Installing TensorFlow 2.10.0...\")\n",
        "\n",
        "    # Step 2: Uninstall current TensorFlow version\n",
        "    !pip uninstall -y tensorflow\n",
        "\n",
        "    # Step 3: Install TensorFlow 2.10.0\n",
        "    !pip install tensorflow==2.10.0\n",
        "\n",
        "    # Step 4: After installation, you should restart the runtime manually\n",
        "    print(\"Please restart the runtime for the changes to take effect.\")\n",
        "\n",
        "    # Once restarted, you can verify the version with the following:\n",
        "    # import tensorflow as tf\n",
        "    # print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *Note*: If you have the tokenizer.pkl file and the sentiment_model.h5 file, jump directly to section \"Model Load\""
      ],
      "metadata": {
        "id": "bJ5nS4W8sMlb"
      },
      "id": "bJ5nS4W8sMlb"
    },
    {
      "cell_type": "markdown",
      "id": "c7ad5ab0",
      "metadata": {
        "id": "c7ad5ab0"
      },
      "source": [
        "## Load and Preprocess Data:\n",
        "\n",
        "### Download the NLP dataset Amazon Sentiment Review form Kaggle\n",
        "#### https://www.kaggle.com/datasets/bittlingmayer/amazonreviews\n",
        "\n",
        "- Reads each line, splits it to separate the label from the review, assigns binary labels (1 for positive, 0 for negative), and stores the results in lists.\n",
        "\n",
        "- Converts the label list to a NumPy array for further processing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "992745e5",
      "metadata": {
        "id": "992745e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "7c5047ce-a535-4162-c0b1-c7589b379cf4"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'Dataset/train.txt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-ab510efb3b91>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Preprocess the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Dataset/train.txt'"
          ]
        }
      ],
      "source": [
        "# Load the data (example path, replace with your actual path)\n",
        "file_path= 'train.txt'\n",
        "\n",
        "# Preprocess the data\n",
        "with open(file_path, 'r', encoding='utf-8') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "labels = []\n",
        "reviews = []\n",
        "for line in lines:\n",
        "    split_line = line.strip().split(' ', 1)\n",
        "    label = 1 if split_line[0] == '__label__2' else 0\n",
        "    review = split_line[1]\n",
        "    labels.append(label)\n",
        "    reviews.append(review)\n",
        "\n",
        "labels = np.array(labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2a2b587",
      "metadata": {
        "id": "f2a2b587"
      },
      "source": [
        "## Tokenization and Sequence Padding:\n",
        "\n",
        "- Initializes a Tokenizer object, specifying a maximum vocabulary size of 10,000 words and an out-of-vocabulary token <OOV>.\n",
        "- Fits the tokenizer on the collected reviews, creating an index of all unique words.\n",
        "- Converts the reviews into lists of integers based on the tokenizer's word index.\n",
        "- Pads these sequences to a fixed length of 250, ensuring all input data has consistent dimensions, necessary for training neural networks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "edfcccbf",
      "metadata": {
        "id": "edfcccbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "eac90f4f-d5fb-4064-d729-c69c2447865b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'reviews' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-0efd9c6af09c>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Tokenizing and padding text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moov_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"<OOV>\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_on_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviews\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0msequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviews\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpadded_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'reviews' is not defined"
          ]
        }
      ],
      "source": [
        "# Tokenizing and padding text\n",
        "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(reviews)\n",
        "sequences = tokenizer.texts_to_sequences(reviews)\n",
        "padded_sequences = pad_sequences(sequences, padding='post', maxlen=250)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62aea0f6",
      "metadata": {
        "id": "62aea0f6"
      },
      "source": [
        "## Loading Pre-trained GloVe Embeddings\n",
        "\n",
        "### Download the Glove Embedding from Kaggle\n",
        "\n",
        "####  https://www.kaggle.com/datasets/danielwillgeorge/glove6b100dtxt\n",
        "\n",
        "- Defines a function to load the GloVe (Global Vectors for Word Representation) embeddings.\n",
        "- Reads the GloVe file, parsing each line to extract the word and its corresponding coefficient vector.\n",
        "- Creates an embedding matrix that maps each word in the tokenizer's index to its GloVe vector, if available. Words not in GloVe will have a vector of zeros.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a44dac7b",
      "metadata": {
        "id": "a44dac7b"
      },
      "outputs": [],
      "source": [
        "# # Load pre-trained GloVe embeddings\n",
        "\n",
        "def load_glove_embeddings(path, word_index, embedding_dim):\n",
        "    embeddings_index = {}\n",
        "    # Open the file with UTF-8 encoding specified\n",
        "    with open(path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            word, coefs = line.split(maxsplit=1)\n",
        "            coefs = np.fromstring(coefs, 'f', sep=' ')\n",
        "            embeddings_index[word] = coefs\n",
        "\n",
        "    # Prepare embedding matrix\n",
        "    num_words = min(len(word_index) + 1, 10000)\n",
        "    embedding_matrix = np.zeros((num_words, embedding_dim))\n",
        "    for word, i in word_index.items():\n",
        "        if i >= num_words:\n",
        "            continue\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:  # Corrected line here\n",
        "            # Use the embedding vector for words found in the GloVe index\n",
        "            embedding_matrix[i] = embedding_vector  # words not found will be all-zeros.\n",
        "\n",
        "    return embedding_matrix\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8800fc79",
      "metadata": {
        "id": "8800fc79"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 100  # Size of the GloVe vectors you're using\n",
        "glove_path = 'Embedding/glove.6B.100d/glove.6B.100d.txt'\n",
        "embedding_matrix = load_glove_embeddings(glove_path, tokenizer.word_index, embedding_dim)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ed572bf",
      "metadata": {
        "id": "5ed572bf"
      },
      "source": [
        "## Model Definition and Compilation:\n",
        "\n",
        "- Defines a sequential model for sentiment analysis.\n",
        "- Adds an Embedding layer to transform indices into dense vectors of fixed size.\n",
        "- Utilizes Bidirectional layers with LSTM units to capture patterns from both forward and backward states of the input sequence.\n",
        "- Adds Dense layers with ReLU activation for non-linear transformations and a dropout layer to reduce overfitting.\n",
        "- The final output layer uses a sigmoid activation function for binary classification.\n",
        "- Compiles the model with the Adam optimizer and binary cross-entropy loss function, tracking accuracy as a metric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d8b02df",
      "metadata": {
        "id": "2d8b02df"
      },
      "outputs": [],
      "source": [
        "# Build the model\n",
        "model = Sequential([\n",
        "    Embedding(10000, embedding_dim, embeddings_initializer=Constant(embedding_matrix),\n",
        "              input_length=250, trainable=False),\n",
        "    Bidirectional(LSTM(128, return_sequences=True)),\n",
        "    Dropout(0.5),\n",
        "    Bidirectional(LSTM(128)),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce4fa260",
      "metadata": {
        "id": "ce4fa260"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3c4e6a3",
      "metadata": {
        "id": "a3c4e6a3"
      },
      "outputs": [],
      "source": [
        "# Splitting the data\n",
        "X_train, X_val, y_train, y_val = train_test_split(padded_sequences, labels, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddafc948",
      "metadata": {
        "id": "ddafc948"
      },
      "source": [
        "## Model Training:\n",
        "\n",
        "- Trains the model on the padded text sequences and labels.\n",
        "- Runs for 5 epochs with 20% of the data reserved for validation to monitor performance and mitigate overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "596a0174",
      "metadata": {
        "id": "596a0174"
      },
      "outputs": [],
      "source": [
        "# Training the model\n",
        "history = model.fit(X_train, y_train, epochs=5, batch_size=64, validation_data=(X_val, y_val), verbose=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "039f21c0",
      "metadata": {
        "id": "039f21c0"
      },
      "source": [
        "## Save the Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4693576",
      "metadata": {
        "id": "e4693576"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "model.save('sentiment_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e1b099f",
      "metadata": {
        "id": "2e1b099f"
      },
      "outputs": [],
      "source": [
        "# Save the tokenizer\n",
        "import pickle\n",
        "with open('tokenizer.pkl', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66daf062",
      "metadata": {
        "id": "66daf062"
      },
      "source": [
        "## Evaluate\n",
        "\n",
        "- Evaluate the model Validation loss\n",
        "- Evaluate the model Validation accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b64ef635",
      "metadata": {
        "id": "b64ef635"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_val, y_val)\n",
        "print(\"Validation loss:\", loss)\n",
        "print(\"Validation accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54a7aec7",
      "metadata": {
        "id": "54a7aec7"
      },
      "outputs": [],
      "source": [
        "#  plot the training history to visualize the learning over epochs:\n",
        "import matplotlib.pyplot as plt\n",
        "# Plotting training history\n",
        "plt.plot(history.history['accuracy'], label='Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1590396",
      "metadata": {
        "id": "f1590396"
      },
      "source": [
        "## Model Load\n",
        "\n",
        "- load the sentiment_model.h5 model from you dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "57021426",
      "metadata": {
        "id": "57021426"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the model\n",
        "model = load_model('sentiment_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "9acdbe1f",
      "metadata": {
        "id": "9acdbe1f"
      },
      "outputs": [],
      "source": [
        "# Load tokenizer\n",
        "with open('tokenizer.pkl', 'rb') as f:\n",
        "    tokenizer = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "b44fd582",
      "metadata": {
        "id": "b44fd582"
      },
      "outputs": [],
      "source": [
        "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbf51b83",
      "metadata": {
        "id": "bbf51b83"
      },
      "source": [
        "## Utility Functions for Text Preprocessing and Sentiment Prediction:\n",
        "\n",
        "- preprocess_text converts input texts into padded sequences suitable for model input, using the previously defined tokenizer.\n",
        "- predict_sentiment processes texts, makes predictions with the trained model, and interprets the results as 'Positive' or 'Negative' based on the prediction score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "de6eac0b",
      "metadata": {
        "id": "de6eac0b"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(texts, tokenizer, max_length=250):\n",
        "    sequences = tokenizer.texts_to_sequences(texts)\n",
        "    padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
        "    return padded_sequences\n",
        "\n",
        "def predict_sentiment(texts, model, tokenizer):\n",
        "    preprocessed_texts = preprocess_text(texts, tokenizer)\n",
        "    predictions = model.predict(preprocessed_texts)\n",
        "    print(\"predictions\",predictions)\n",
        "    sentiment_labels = ['Negative' if pred < 0.5 else 'Positive' for pred in predictions.flatten()]\n",
        "    return sentiment_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a58a1314",
      "metadata": {
        "id": "a58a1314"
      },
      "source": [
        "## Sentiment Prediction on New Reviews:\n",
        "\n",
        "- Lists new review texts to test the model.\n",
        "- Calls predict_sentiment to determine the sentiment of each review.\n",
        "- Prints out each review with its predicted sentiment, providing a practical demonstration of the model in action."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "d95588b0",
      "metadata": {
        "scrolled": true,
        "id": "d95588b0",
        "outputId": "8aafec37-650a-481b-dbb7-ea269808562b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "predictions [[9.9729866e-01]\n",
            " [5.6705908e-03]\n",
            " [7.6428093e-02]\n",
            " [9.9134994e-01]\n",
            " [7.4565579e-04]\n",
            " [1.5018794e-01]\n",
            " [9.8866230e-01]]\n",
            "Review: I absolutely loved this product, it worked wonders for me!\n",
            "Sentiment: Positive\n",
            "\n",
            "Review: Horrible experience, it broke down the first time I used it.\n",
            "Sentiment: Negative\n",
            "\n",
            "Review: Okay product, but I expected something better.\n",
            "Sentiment: Negative\n",
            "\n",
            "Review: Perfect, just as described! Would buy again!\n",
            "Sentiment: Positive\n",
            "\n",
            "Review: Not worth the money, very disappointing.\n",
            "Sentiment: Negative\n",
            "\n",
            "Review: If you want to listen to El Duke , then it is better if you have access to his shower,this is not him, it is a gimmick,very well orchestrated.\n",
            "Sentiment: Negative\n",
            "\n",
            "Review: Review of Kelly Club for Toddlers: For the price of 7.99, this PC game is WELL worth it, great graphics, colorful and lots to do! My four year old daughter is in love with the many tasks to complete in this game, including dressing and grooming wide variety of pets and decoration of numerous floats to show in your little one's very own parade.\n",
            "Sentiment: Positive\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Example reviews\n",
        "new_reviews = [\n",
        "    \"I absolutely loved this product, it worked wonders for me!\",\n",
        "    \"Horrible experience, it broke down the first time I used it.\",\n",
        "    \"Okay product, but I expected something better.\",\n",
        "    \"Perfect, just as described! Would buy again!\",\n",
        "    \"Not worth the money, very disappointing.\",\n",
        "    \"If you want to listen to El Duke , then it is better if you have access to his shower,this is not him, it is a gimmick,very well orchestrated.\",\n",
        "     \"Review of Kelly Club for Toddlers: For the price of 7.99, this PC game is WELL worth it, great graphics, colorful and lots to do! My four year old daughter is in love with the many tasks to complete in this game, including dressing and grooming wide variety of pets and decoration of numerous floats to show in your little one's very own parade.\"\n",
        "]\n",
        "\n",
        "# Predict sentiments\n",
        "sentiments = predict_sentiment(new_reviews, model, tokenizer)\n",
        "# print(sentiments)\n",
        "for review, sentiment in zip(new_reviews, sentiments):\n",
        "    print(f\"Review: {review}\\nSentiment: {sentiment}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "6a3b88ac",
      "metadata": {
        "id": "6a3b88ac",
        "outputId": "1cc7b1cb-8661-49c7-b1d7-4559ff51fa0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 149ms/step\n",
            "Prediction: [0.00288917]\n",
            "Review: very bad product\n",
            "Sentiment: Negative\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def preprocess_text(text, tokenizer, max_length=250):\n",
        "    sequence = tokenizer.texts_to_sequences([text])\n",
        "    padded_sequence = pad_sequences(sequence, maxlen=max_length, padding='post')\n",
        "    return padded_sequence\n",
        "\n",
        "def predict_sentiment(text, model, tokenizer):\n",
        "    preprocessed_text = preprocess_text(text, tokenizer)\n",
        "    prediction = model.predict(preprocessed_text)[0]\n",
        "    print(\"Prediction:\", prediction)\n",
        "    sentiment_label = 'Negative' if prediction < 0.5 else 'Positive'\n",
        "    return sentiment_label\n",
        "\n",
        "# Example review\n",
        "new_review = \"very bad product\"\n",
        "\n",
        "# Predict sentiment\n",
        "sentiment = predict_sentiment(new_review, model, tokenizer)\n",
        "print(f\"Review: {new_review}\\nSentiment: {sentiment}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f35e0602",
      "metadata": {
        "id": "f35e0602"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}